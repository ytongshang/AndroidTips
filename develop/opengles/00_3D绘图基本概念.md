# 3D绘图基本概念

## 参考资料

- [LearnOpenGL CN](https://learnopengl-cn.github.io/)
- [OpenGL教程](https://blog.csdn.net/junzia/article/list/3)
- [OpenGL-投影和摄像机](https://cloud.tencent.com/developer/article/1015587)
- [OpenGL 学习系列---投影矩阵](https://juejin.im/post/5b0ec5fef265da092a2b79b1)

## Vertex Array

- Android中使用ByteBuffer存储我们定义的顶点数组数据

```java
private final float vertices[] = {
    -0.5f, 0.5f, 0.0f,  // 0, Top Left
    -0.5f, -0.5f, 0.0f,  // 1, Bottom Left
    0.5f, -0.5f, 0.0f,  // 2, Bottom Right
    0.5f, 0.5f, 0.0f,  // 3, Top Right
};

private final FloatBuffer vertexBuffer;

// 每个float有4位
ByteBuffer vb = ByteBuffer.allocateDirect(vertices.length * 4);
vb.order(ByteOrder.nativeOrder());
vertexBuffer = vb.asFloatBuffer();
vertexBuffer.put(vertices);
vertexBuffer.position(0);
```

## 图形渲染管线(Graphics Pipeline)

- 图形渲染管线接受一组3D坐标，然后把它们转变为你屏幕上的有色2D像素输出。
- 图形渲染管线可以被划分为几个阶段，**每个阶段将会把前一个阶段的输出作为输入**。所有这些阶段都是高度专门化的（它们都有一个特定的函数），并且很容易并行执行。正是由于它们具有并行执行的特性，当今大多数显卡都有成千上万的小处理核心，它们在GPU上为每一个（渲染管线）阶段运行各自的小程序，从而在图形渲染管线中快速处理你的数据。**这些小程序叫做着色器(Shader)**.
- 有些着色器允许开发者自己配置，这就允许我们用自己写的着色器来替换默认的。这样我们就可以更细致地控制图形渲染管线中的特定部分了，而且因为它们运行在GPU上，所以它们可以给我们节约宝贵的CPU时间
- 下图为图形渲染管线的每个阶段的抽象展示，**蓝色部分代表的是我们可以注入自定义的着色器的部分**

![Graphics Pipeline](../../image-resources/opengl/pipeline.png)

## 变换

### 矩阵

#### 单位矩阵

![单位矩阵](../../image-resources/opengl/单位矩阵.png)

#### 缩放

- 如果我们把缩放变量表示为(S1,S2,S3)我们可以为任意向量(x,y,z)定义一个缩放矩阵

![缩放矩阵](../../image-resources/opengl/缩放矩阵.png)

#### 位移

- 如果我们把位移向量表示为(Tx,Ty,Tz)，我们就能把位移矩阵定义为：

![位移矩阵](../../image-resources/opengl/位移矩阵.png)

#### 旋转

- 旋转矩阵在3D空间中每个单位轴都有不同定义，旋转角度用θ表示

- 沿X轴旋转

![沿X轴旋转](../../image-resources/opengl/沿X轴旋转.png)

- 沿Y轴旋转

![沿Y轴旋转](../../image-resources/opengl/沿Y轴旋转.png)

- 沿Z轴旋转

![沿Z轴旋转](../../image-resources/opengl/沿Z轴旋转.png)

#### 矩阵的组合

- 假设我们有一个顶点(x, y, z)，我们希望将其缩放2倍，然后位移(1, 2, 3)个单位。我们需要一个位移和缩放矩阵来完成这些变换
- **矩阵按我们想要操作的顺序从右向左书写**

![矩阵组合](../../image-resources/opengl/矩阵组合.png)

## 坐标系统

### 坐标变换

- 坐标系总结
  - 局部空间(Local Space，或者称为物体空间(Object Space))
  - 世界空间(World Space)
  - 观察空间(View Space，或者称为视觉空间(Eye Space))
  - 裁剪空间(Clip Space)
  - 屏幕空间(Screen Space)
- 为了将坐标从一个坐标系变换到另一个坐标系，我们需要用到几个变换矩阵，最重要的几个分别是模型(Model)、观察(View)、投影(Projection)三个矩阵。我们的顶点坐标起始于局部空间(Local Space)，在这里它称为局部坐标(Local Coordinate)，它在之后会变为世界坐标(World Coordinate)，观察坐标(View Coordinate)，裁剪坐标(Clip Coordinate)，并最后以屏幕坐标(Screen Coordinate)的形式结束。下面的这张图展示了整个流程以及各个变换过程做了什么：

![坐标系统](../../image-resources/opengl/coordinate_systems.png)

- 一个顶点坐标将会根据以下过程被变换到裁剪坐标：注意矩阵运算的顺序是相反的（记住我们需要从右往左阅读矩阵的乘法）。最后的顶点应该被赋值到顶点着色器中的gl_Position，OpenGL将会自动进行透视除法和裁剪

![Opengl中顶点矩阵变换](../../image-resources/opengl/Opengl中顶点矩阵变换.png)

- 转换成Shader脚本

```glsl
attribute vec4 a_Position;
uniform mat4 u_ModelMatrix;
uniform mat4 u_ProjectionMatrix;
uniform mat4 u_ViewMatrix;
void main()
{
    gl_Position  = u_ProjectionMatrix * u_ViewMatrix * u_ModelMatrix * a_Position;
}
```

### 局部空间

- 局部空间是指物体所在的坐标空间，即对象最开始所在的地方

### 世界空间

- **物体的坐标从局部变换到世界空间，该变换是由模型矩阵(Model Matrix)实现的**
- 模型矩阵是一种变换矩阵，它能通过对物体进行位移、缩放、旋转来将它置于它本应该在的位置或朝向

### 观察空间

- 观察空间经常被人们称之OpenGL的摄像机(Camera)。
- 观察空间是将世界空间坐标转化为用户视野前方的坐标而产生的结果。因此观察空间就是从摄像机的视角所观察到的空间。而这通常是由一系列的位移和旋转的组合来完成，平移/旋转场景从而使得特定的对象被变换到摄像机的前方。**这些组合在一起的变换通常存储在一个观察矩阵(View Matrix)里，它被用来将世界坐标变换到观察空间**
- 使用Matrix.setLookAtM()来设置摄像机位置,**在设置up向量时，一般总是设置为(0,1,0)**
  - 第一组eyex, eyey,eyez 相机在世界坐标的位置
  - 第二组centerx,centery,centerz 相机镜头对准的物体在世界坐标的位置
  - 第三组upx,upy,upz 相机向上的方向在世界坐标中的方向
  - 第一组眼睛就相当于你的头在一个三维坐标中的具体坐标。
  - 第二组就是你眼睛要看的物体的坐标。
  - 第三组就是你的头的方向。
  - 如果你把upx=0;upz=0;upy=1,那么说明你的头是正常人一样的方向，如果upy=-1那么就相当于你是倒立的。
  - 如果upx=1;upz=0;upy=0；那么相当于我们看的是右边，如果upx=-1，就相当于看的左边。
  - 如果upx=0;upz=1;upy=0；相当于我们看的是屏幕朝我们的方向，如果upz=-1,相当于我们看的是屏幕向里的方向。

```java
    /**
     *
     * @param rm 生成的摄像机矩阵，float[16]
     * @param rmOffset 填充时候的起始偏移量
     * @param eyeX 摄像机x坐标
     * @param eyeY 摄像机y坐标
     * @param eyeZ 摄像机z坐标
     * @param centerX 观察目标点的x坐标
     * @param centerY 观察目标点的y坐标
     * @param centerZ 观察目标点的z坐标
     * @param upX 摄像机up向量在x上的分量
     * @param upY 摄像机up向量在y上的分量
     * @param upZ 摄像机up向量在z上的分量
     */
    public static void setLookAtM(float[] rm, int rmOffset,
            float eyeX, float eyeY, float eyeZ,
            float centerX, float centerY, float centerZ, float upX, float upY,
            float upZ) {
    }
```

### 裁剪空间

- 在一个顶点着色器运行的最后，OpenGL期望所有的坐标都能落在一个特定的范围内，且任何在这个范围之外的点都应该被裁剪掉(Clipped)。被裁剪掉的坐标就会被忽略，所以剩下的坐标就将变为屏幕上可见的片段
- 因为将所有可见的坐标都指定在-1.0到1.0的范围内不是很直观，所以**我们会指定自己的坐标集(Coordinate Set)并将它变换回标准化设备坐标系**
- **为了将顶点坐标从观察变换到裁剪空间，我们需要定义一个投影矩阵(Projection Matrix)**，它指定了一个范围的坐标
- **由投影矩阵创建的观察箱(Viewing Box)被称为平截头体(Frustum)，每个出现在平截头体范围内的坐标都会最终出现在用户的屏幕上**。将特定范围内的坐标转化到标准化设备坐标系的过程（而且它很容易被映射到2D观察空间坐标）被称之为投影(Projection)，因为使用投影矩阵能将3D坐标投影(Project)到很容易映射到2D的标准化设备坐标系中

![视景体](../../image-resources/opengl/视景体.png)

### 正交投影

- 不管是正交投影还是透视投影，最终都是**将视景体内的物体投影在近平面上**，这也是3D坐标转换到2D坐标的关键一步。**而近平面上的坐标接着也会转换成归一化设备坐标，再映射到屏幕视口上。**

![正交投影图解](../../image-resources/opengl/正交投影图解.png)

- **需要注意的是，我们的左、上、右、下距离都是相对于近平面中心的**。近平面的坐标原点位于中心，向右为X轴正方向，向上为Y轴正方向，所以**我们的left、bottom要为负数，而right、top要为正数**。
- 同时，近平面和远平面的距离都是指相对于视点的距离，所以 near、far 要为正数，而且 far > near。

```java
    /**
     * @param m 生成的投影矩阵,float[4*4]
     * @param mOffset 填充时候起始的偏移量
     * @param left  近平面left边的x坐标
     * @param right 近平面right边的x坐标
     * @param bottom  近平面bottom边的y坐标
     * @param top   近平面top边的y坐标
     * @param near  近平面距离摄像机的距离
     * @param far   远平面距离摄像机的距离
     */
    public static void orthoM(float[] m, int mOffset,
        float left, float right, float bottom, float top,
        float near, float far) {
}
```

- **为了保证图像不被拉伸，就是要保证近平面的宽高比和视口的宽高比一致，而且是以较短的那一边作为1的标准，让图像保持居中**

```java
    @Override
    public void onSurfaceChanged(GL10 gl, int width, int height) {
        float aspectRatio = width > height ? (float) width / (float) height : (float) height / (float) width;
        if (width > height){
            Matrix.orthoM(projectionMatrix,0,-aspectRatio,aspectRatio,-1f,1f,0f,10f);
        }else {
            Matrix.orthoM(projectionMatrix,0,-1f,1f,-aspectRatio,aspectRatio,0f,10f);
        }
    }
```

### 透视投影

- 透视投影是能够产生近大远小效果

![透视投影](../../image-resources/opengl/opengl_frustum.png)

![透视投影分析](../../image-resources/opengl/opengl_frustum_analysis.png)

#### frustumM

- **frustumM,它的视景体有点类似于正交投影，在参数理解上基本都相同的**
- 需要注意的是 near 和 far 变量的值必须要大于0。因为它们都是相对于视点的距离，也就是照相机的距离。
- 当用视图矩阵确定了照相机的位置时，**要确保物体距离视点的位置在 near和 far的区间范围内，否则就会看不到物体。**由于透视投影会产生近大远小的效果，当照相机位置不变，改变near的值时也会改变物体大小，near越小,则离视点越近，相当于物体越远，那么显示的物体也就越小了。当然也可以near和far的距离不动，改变摄像机的位置来改变观察到的物体大小

```java
/**
     * Defines a projection matrix in terms of six clip planes.
     *
     * @param m the float array that holds the output perspective matrix
     * @param offset the offset into float array m where the perspective
     *        matrix data is written
     * @param left
     * @param right
     * @param bottom
     * @param top
     * @param near
     * @param far
     */
    public static void frustumM(float[] m, int offset,
            float left, float right, float bottom, float top,
            float near, float far)

```

#### perspectiveM

![opengl_perspectiveM](../../image-resources/opengl/opengl_perspectiveM.jpg)

- 下面图片左边是 90 视角，右边是 45 度视角。显然，视野角度越大，则看到的内容更多，但是物体显得更小，而视野角度越小，则看的内容更少，但物体显得更大

![透视投影示例](../../image-resources/opengl/透视投影示例.png)